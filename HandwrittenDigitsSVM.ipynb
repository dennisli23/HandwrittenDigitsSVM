{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.misc import imread # using scipy's imread\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def boundaries(binarized,axis):\n",
    "    # variables named assuming axis = 0; algorithm valid for axis=1\n",
    "    # [1,0][axis] effectively swaps axes for summing\n",
    "    rows = np.sum(binarized,axis = [1,0][axis]) > 0\n",
    "    rows[1:] = np.logical_xor(rows[1:], rows[:-1])\n",
    "    change = np.nonzero(rows)[0]\n",
    "    ymin = change[::2]\n",
    "    ymax = change[1::2]\n",
    "    height = ymax-ymin\n",
    "    too_small = 10 # real letters will be bigger than 10px by 10px\n",
    "    ymin = ymin[height>too_small]\n",
    "    ymax = ymax[height>too_small]\n",
    "    return zip(ymin,ymax)\n",
    "\n",
    "def separate(img):\n",
    "    orig_img = img.copy()\n",
    "    pure_white = 255.\n",
    "    white = np.max(img)\n",
    "    black = np.min(img)\n",
    "    thresh = (white+black)/2.0\n",
    "    binarized = img<thresh\n",
    "    row_bounds = boundaries(binarized, axis = 0) \n",
    "    cropped = []\n",
    "    for r1,r2 in row_bounds:\n",
    "        img = binarized[r1:r2,:]\n",
    "        col_bounds = boundaries(img,axis=1)\n",
    "        rects = [r1,r2,col_bounds[0][0],col_bounds[0][1]]\n",
    "        cropped.append(np.array(orig_img[rects[0]:rects[1],rects[2]:rects[3]]/pure_white))\n",
    "    return cropped\n",
    "\n",
    "# Example usage\n",
    "big_img = imread(\"a.png\", flatten = True)# flatten = True converts to grayscale\n",
    "cv2.imshow(\"a\",big_img/255)\n",
    "cv2.waitKey(1000)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "imgs = separate(big_img) # separates big_img (pure white = 255) into array of little images (pure white = 1.0)\n",
    "for img in imgs:\n",
    "    cv2.imshow(\"a\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnA = imread(\"a.png\", flatten = True)\n",
    "imgsA = separate(columnA)\n",
    "for img in imgsA:\n",
    "    cv2.imshow(\"a\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnB = imread(\"b.png\", flatten = True)\n",
    "imgsB = separate(columnB)\n",
    "for img in imgsB:\n",
    "    cv2.imshow(\"a\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnC = imread(\"c.png\", flatten = True)\n",
    "imgsC = separate(columnC)\n",
    "for img in imgsC:\n",
    "    cv2.imshow(\"a\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fun(imgs, data):\n",
    "    for img in imgs:\n",
    "        scaled = cv2.resize(img, (5,5), interpolation = cv2.INTER_CUBIC)\n",
    "        img = np.array(scaled)\n",
    "        data.append(img.flatten())\n",
    "dataA = []\n",
    "dataB = []\n",
    "dataC = []\n",
    "fun(imgsA, dataA)\n",
    "fun(imgsB, dataB)\n",
    "fun(imgsC, dataC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataA = np.array(dataA)\n",
    "dataB = np.array(dataB)\n",
    "dataC = np.array(dataC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69, 25)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate((dataA, dataB, dataC))\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69,)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetA = [0]*23\n",
    "targetB = [1]*23\n",
    "targetC = [2]*23\n",
    "target = np.concatenate((targetA, targetB, targetC))\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#my own handwriting\n",
    "columnE = imread(\"e.JPG\", flatten = True)\n",
    "imgsE = separate(columnE)\n",
    "for img in imgsE:\n",
    "    cv2.imshow(\"e\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnD = imread(\"d.JPG\", flatten = True)\n",
    "imgsD = separate(columnD)\n",
    "for img in imgsD:\n",
    "    cv2.imshow(\"d\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columnH = imread(\"h.JPG\", flatten = True)\n",
    "imgsH = separate(columnH)\n",
    "for img in imgsH:\n",
    "    cv2.imshow(\"h\",img) \n",
    "    cv2.waitKey(250)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataD = []\n",
    "dataE = []\n",
    "dataH = []\n",
    "fun(imgsD, dataD)\n",
    "fun(imgsE, dataE)\n",
    "fun(imgsH, dataH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dataD = np.array(dataD)\n",
    "dataE = np.array(dataE)\n",
    "dataH = np.array(dataH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18, 25)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = np.concatenate((dataD, dataE, dataH))\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18,)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targetD = [0]*6\n",
    "targetE = [1]*6\n",
    "targetH = [2]*6\n",
    "target = np.concatenate((targetD, targetE, targetH))\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition(data, target, p):\n",
    "    train_data = []\n",
    "    train_target = []\n",
    "    test_data = []\n",
    "    test_target = []\n",
    "    train_size = int(len(target)*p)\n",
    "    test_size = len(target)-train_size\n",
    "    duplicates = []\n",
    "    \n",
    "    index = np.random.randint(len(target))\n",
    "    for i in range(train_size):\n",
    "        while index in duplicates:\n",
    "            index = np.random.randint(len(target))\n",
    "        duplicates.append(index)\n",
    "        train_data.append(data[index])\n",
    "        train_target.append(target[index])\n",
    "    \n",
    "       \n",
    "    index = np.random.randint(len(target))\n",
    "    for i in range(test_size):\n",
    "        while index in duplicates:\n",
    "            index = np.random.randint(len(target))\n",
    "        duplicates.append(index)\n",
    "        test_data.append(data[index])\n",
    "        test_target.append(target[index])\n",
    "    \n",
    "    return train_data, train_target, test_data, test_target, test_size\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data, train_target, test_data, test_target, test_size = partition(data, target, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'svm' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-39-cd63e623bd08>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mlinearModel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msvm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mlinearModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_target\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinearModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'svm' is not defined"
     ]
    }
   ],
   "source": [
    "import sklearn\n",
    "linearModel = svm.LinearSVC()\n",
    "linearModel.fit(train_data, train_target)\n",
    "predicted = linearModel.predict(test_data)\n",
    "matches = 0\n",
    "for i in range(test_size):\n",
    "    if predicted[i] == test_target[i]:\n",
    "        matches = matches + 1\n",
    "        \n",
    "accuracy = float(matches)/test_size * 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print \"Predicted: \" + str(predicted) + \"\\nTruth: \" + str(test_target) + \"\\nAccuracy: \" + str(accuracy) + \"%\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
